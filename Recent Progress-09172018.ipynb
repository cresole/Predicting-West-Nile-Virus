{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./all/train.csv\")\n",
    "weather = pd.read_csv(\"./all/weather.csv\")\n",
    "spray = pd.read_csv(\"./all/spray.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10506 entries, 0 to 10505\n",
      "Data columns (total 12 columns):\n",
      "Date                      10506 non-null object\n",
      "Address                   10506 non-null object\n",
      "Species                   10506 non-null object\n",
      "Block                     10506 non-null int64\n",
      "Street                    10506 non-null object\n",
      "Trap                      10506 non-null object\n",
      "AddressNumberAndStreet    10506 non-null object\n",
      "Latitude                  10506 non-null float64\n",
      "Longitude                 10506 non-null float64\n",
      "AddressAccuracy           10506 non-null int64\n",
      "NumMosquitos              10506 non-null int64\n",
      "WnvPresent                10506 non-null int64\n",
      "dtypes: float64(2), int64(4), object(6)\n",
      "memory usage: 985.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14835 entries, 0 to 14834\n",
      "Data columns (total 4 columns):\n",
      "Date         14835 non-null object\n",
      "Time         14251 non-null object\n",
      "Latitude     14835 non-null float64\n",
      "Longitude    14835 non-null float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 463.7+ KB\n"
     ]
    }
   ],
   "source": [
    "spray.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10506, 12), (2944, 22), (14835, 4))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, weather.shape, spray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9955\n",
       "1     551\n",
       "Name: WnvPresent, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['WnvPresent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05244622120692937"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "551 / (551 + 9955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-248e8b59d9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "train.Date = pd.to_datetime(df.Date)\n",
    "weather.Date = pd.to_datetime(weather.Date)\n",
    "spray.Date = pd.to_datetime(spray.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdata = np.loadtxt(\"./all/mapdata_copyright_openstreetmap_contributors.txt\")\n",
    "traps = pd.read_csv('./all/train.csv')[['Date', 'Trap','Longitude', 'Latitude', 'WnvPresent']]\n",
    "\n",
    "aspect = mapdata.shape[0] * 1.0 / mapdata.shape[1]\n",
    "lon_lat_box = (-88, -87.5, 41.6, 42.1)\n",
    "\n",
    "#plot map\n",
    "plt.figure(figsize=(10,14))\n",
    "plt.imshow(mapdata, cmap=plt.get_cmap('gray'), extent=lon_lat_box, aspect=aspect)\n",
    "\n",
    "#Spray locations\n",
    "sprays = spray[['Longitude', 'Latitude']].drop_duplicates()\n",
    "sprays = sprays[sprays['Latitude'] < 42.3]  #outliers excluded\n",
    "plt.scatter(sprays['Longitude'], sprays['Latitude'], marker='*', color='orange',alpha=.3, label='Spray Locations')\n",
    "\n",
    "#Trap locations\n",
    "locations = traps[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "plt.scatter(locations[:,0], locations[:,1], marker='x', label='Trap Locations')\n",
    "\n",
    "#Weather locations\n",
    "plt.scatter(x = (-87.933, -87.752), y = (41.995, 41.786), marker='o', color='r', label='Weather Station')\n",
    "            \n",
    "plt.title('West Nile Virus Preventions in Chicago')\n",
    "plt.legend(frameon=1)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.savefig('heatmap.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check columns for the value with M\n",
    "object_features = ['Tavg', 'Depart', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset',\n",
    "       'CodeSum', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal', 'StnPressure',\n",
    "       'SeaLevel', 'AvgSpeed']\n",
    "for col in weather[object_features]:\n",
    "    station_1 = len(weather[(weather[col].str.contains('M')) & (weather.Station==1)])\n",
    "    print(col + ' has ' + str(station_1) + ' missing values at station 1')\n",
    "    station_2 = len(weather[(weather[col].str.contains('M')) & (weather.Station==2)])\n",
    "    print(col + ' has ' + str(station_2) + ' missing values at station 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check columns for values with T\n",
    "for col in weather[object_features]:\n",
    "    station_1 = len(weather[(weather[col].str.contains('T')) & (weather.Station==1)])\n",
    "    print(col + ' has ' + str(station_1) + ' missing values at station 1')\n",
    "    station_2 = len(weather[(weather[col].str.contains('T')) & (weather.Station==2)])\n",
    "    print(col + ' has ' + str(station_2) + ' missing values at station 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to replace values of M, T, - \n",
    "columns = ['Tavg', 'Depart', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset',\n",
    "           'SnowFall', 'PrecipTotal', 'StnPressure','SeaLevel', 'AvgSpeed']\n",
    "\n",
    "for column in columns:\n",
    "    weather.replace({'M': None}, inplace = True)\n",
    "    weather.replace({'T': '0.00001'}, inplace = True)\n",
    "    weather.replace({'  T': '0.00001'}, inplace = True)\n",
    "    weather.replace({'-': None}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't find these columns useful at all\n",
    "weather.drop(columns= ['CodeSum', 'Depth', 'Water1'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert columns to float type and fill na with mean\n",
    "for column in columns:\n",
    "    weather[column] = weather[column].astype(float)\n",
    "    weather[column] = weather[column].fillna(weather[column].mean(skipna = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with the average of columns for the two weather stations\n",
    "weather_both = pd.DataFrame()\n",
    "station_1 = weather[weather['Station'] == 1].reset_index()\n",
    "station_2 = weather[weather['Station'] == 2].reset_index()\n",
    "weather_both['Date'] = station_1['Date']\n",
    "\n",
    "\n",
    "def avg_station(df):\n",
    "    for col in df:\n",
    "        weather_both[col] = (station_1[col] + station_2[col])*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function\n",
    "avg_station(weather.drop(['Date','Station'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the days since it last rained\n",
    "weather_both[\"days_since_rain\"] = 0\n",
    "days = 0\n",
    "\n",
    "for i in range(weather_both.shape[0]):\n",
    "    if weather_both.loc[i,'PrecipTotal'] == 0:\n",
    "        days = days + 1\n",
    "        weather_both.loc[i,'days_since_rain'] = days\n",
    "    else:\n",
    "        weather_both.loc[i, 'days_since_rain'] = 0\n",
    "        days=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure everything is good so far\n",
    "weather_both.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a new dataframe for the features i want to do a time lag on\n",
    "var = ['Tmax', 'Tmin', 'Tavg', 'DewPoint', 'WetBulb', 'SnowFall',\n",
    "       'PrecipTotal', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']\n",
    "\n",
    "lag_features = weather_both[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the number of lags i want, these are the lags in days\n",
    "lags = (1,3,7,14)\n",
    "\n",
    "#set to a final dataframe\n",
    "#.assign assigns new columns to the dataframe, after that is a list comprehension\n",
    "#f'{col}_lag_{n}' <-- f' string feature to assign column name, its like .format()\n",
    "#list comp <-- for every column shift down for every lag\n",
    "final_weather = weather_both.assign(**{f'{col}_lag_{n}': \n",
    "                                       lag_features[col].shift(n) for n in lags for col in lag_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges the two datasets together (train and final weather data)\n",
    "result = train.merge(final_weather, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for how long a day is in minutes\n",
    "def day_length(row):\n",
    "    sunset = (round(row.Sunset / 100) * 60)\n",
    "    sunrise = (round(row.Sunrise / 100) * 60)\n",
    "    return int(abs(sunset - sunrise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function\n",
    "result['day_length'] = result.apply(day_length, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_high_corr = abs(result.corr()[\"WnvPresent\"]).sort_values(ascending=False).round(3).index[2:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result[\"WnvPresent\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the five best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_features = result.drop(columns=['WnvPresent', 'NumMosquitos'], axis = 1)\n",
    "training_features = result[columns_high_corr]\n",
    "training_target = result[\"WnvPresent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(training_features, training_target,\n",
    "                                                  test_size = .2,\n",
    "                                                  random_state=11, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_mod, y_train_mod = sm.fit_sample(x_train, y_train)\n",
    "x_test_mod, y_test_mod = sm.fit_sample(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "\n",
    "print(\"Cross validation on over sampled train data:\\n\",cross_val_score(lg, x_train_mod,y_train_mod,n_jobs=-1, cv = 10).round(3),\"\\n\")\n",
    "\n",
    "print(\"Cross validation on test data: \\n\", cross_val_score(lg, x_test,y_test,n_jobs=-1, cv = 10).round(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.fit(x_train_mod, y_train_mod)\n",
    "predicted = lg.predict(x_train_mod)\n",
    "print(\"R2 score on train dataset: \", lg.score(x_train_mod, y_train_mod).round(3))\n",
    "print(\"ROC score on train dataset: \", roc_auc_score(y_train_mod, predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"R2 score on test dataset: \", lg.score(x_test, y_test).round(3))\n",
    "predicted = lg.predict(x_test)\n",
    "print(\"ROC score on test dataset: \",roc_auc_score(y_test, predicted).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "print(\"Cross validation on train dataset: \\n\", cross_val_score(gbc, x_train_mod,y_train_mod, n_jobs=-1, cv = 10).round(3), \"\\n\")\n",
    "print(\"Cross validation on test dataset: \\n\", cross_val_score(gbc, x_test,y_test, n_jobs=-1, cv = 10).round(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbc.fit(x_train_mod, y_train_mod)\n",
    "predicted = gbc.predict(x_train_mod)\n",
    "print(\"R2 score on train dataset: \", gbc.score(x_train_mod, y_train_mod).round(3))\n",
    "print(\"ROC score on train dataset: \", roc_auc_score(y_train_mod ,predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gbc.predict(x_test)\n",
    "print(\"R2 score on test dataset: \", gbc.score(x_test, y_test).round(3))\n",
    "print(\"ROC score on test dataset: \", roc_auc_score(y_test, predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gridsearch CV to optimize results\n",
    "score_function = make_scorer(roc_auc_score)\n",
    "params_gbc = {\n",
    "    \"gbc__learning_rate\"  : [1],\n",
    "    \"gbc__n_estimators\"     : [10, 100, 300],\n",
    "    \"gbc__max_depth\"  : [3, 10],\n",
    "    \"gbc__random_state\"    : [42]\n",
    "             }\n",
    "steps_gbc = [('gbc', GradientBoostingClassifier())]\n",
    "pipe_gbc = Pipeline(steps = steps_gbc)\n",
    "gs_gbc = GridSearchCV(pipe_gbc, param_grid = params_gbc , scoring = score_function, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_gbc.fit(x_train_mod, y_train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test gbc using gridserachcv updated results\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, random_state=42, max_depth=10)\n",
    "gbc.fit(x_train_mod, y_train_mod)\n",
    "predicted = gbc.predict(x_train_mod)\n",
    "print(\"R2 score on train dataset: \", gbc.score(x_train_mod, y_train_mod).round(3))\n",
    "print(\"ROC score on train dataset: \", roc_auc_score(y_train_mod ,predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gbc.predict(x_test)\n",
    "print(\"R2 score on test dataset: \", gbc.score(x_test, y_test).round(3))\n",
    "print(\"ROC score on test dataset: \", roc_auc_score(y_test, predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune on accuracy score:\n",
    "# {'gbc__learning_rate': 0.1,\n",
    "# 'gbc__max_depth': 10,\n",
    "# 'gbc__n_estimators': 500,\n",
    "# 'gbc__random_state': 42}\n",
    "# R2 score on train dataset:  0.903\n",
    "# ROC score on train dataset:  0.903\n",
    "# R2 score on test dataset:  0.846\n",
    "# ROC score on test dataset:  0.682   too bad on ROC score, switch to ROC score for score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc = GradientBoostingClassifier(learning_rate=1, n_estimators=100, random_state=42, max_depth=10)\n",
    "# R2 score on train dataset:  0.962\n",
    "# ROC score on train dataset:  0.962\n",
    "# R2 score on test dataset:  0.903\n",
    "# ROC score on test dataset:  0.625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc = GradientBoostingClassifier(learning_rate=0.1, n_estimators=500, random_state=42, max_depth=10)\n",
    "# R2 score on train dataset:  0.965\n",
    "# ROC score on train dataset:  0.965\n",
    "# R2 score on test dataset:  0.92\n",
    "# ROC score on test dataset:  0.607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth=5)\n",
    "#print(\"Cross validation score on train dataset: \", cross_val_score(rfc, x_train_mod,y_train_mod, n_jobs=-1).round(3), \"\\n\")\n",
    "#print(\"Cross validation score on test dataset: \", cross_val_score(rfc, x_test,y_test, n_jobs=-1).round(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cf2d67fe21a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R2 score on train dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC score on train dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_mod' is not defined"
     ]
    }
   ],
   "source": [
    "rfc.fit(x_train_mod, y_train_mod)\n",
    "print(\"R2 score on train dataset: \", rfc.score(x_train_mod, y_train_mod).round(3))\n",
    "predicted = rfc.predict(x_train)\n",
    "print(\"ROC score on train dataset: \", roc_auc_score(y_train, predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score on test dataset: \", rfc.score(x_test, y_test).round(3))\n",
    "predicted = rfc.predict(x_test)\n",
    "print(\"ROC score on test dataset: \", roc_auc_score(y_test, predicted).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** XGBOOST Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-661-a7dda6cb33fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                            \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                            missing=None)\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0my_pro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[1;32m    545\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                evaluation_result_list=evaluation_result_list))\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEarlyStopException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;34m\"\"\"internal function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=7,\n",
    "                           min_child_weight=1,\n",
    "                           learning_rate=0.1,\n",
    "                           n_estimators=500,\n",
    "                           silent=True,\n",
    "                           objective='binary:logistic',\n",
    "                           gamma=0,\n",
    "                           max_delta_step=0,\n",
    "                           subsample=1,\n",
    "                           colsample_bytree=1,\n",
    "                           colsample_bylevel=1,\n",
    "                           reg_alpha=0,\n",
    "                           reg_lambda=0,\n",
    "                           scale_pos_weight=1,\n",
    "                           seed=1,\n",
    "                           missing=None)\n",
    "xgb.fit(x_train_mod, y_train_mod, eval_metric='auc', verbose=False, early_stopping_rounds=100)\n",
    "y_pre = xgb.predict(x_test)\n",
    "y_pro = xgb.predict_proba(x_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create Sumission File for Kaggle **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kaggle = pd.read_csv(\"./all/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 11)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116293 entries, 0 to 116292\n",
      "Data columns (total 11 columns):\n",
      "Id                        116293 non-null int64\n",
      "Date                      116293 non-null object\n",
      "Address                   116293 non-null object\n",
      "Species                   116293 non-null object\n",
      "Block                     116293 non-null int64\n",
      "Street                    116293 non-null object\n",
      "Trap                      116293 non-null object\n",
      "AddressNumberAndStreet    116293 non-null object\n",
      "Latitude                  116293 non-null float64\n",
      "Longitude                 116293 non-null float64\n",
      "AddressAccuracy           116293 non-null int64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test_kaggle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to apply the same feature engineering steps for better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kaggle.Date = pd.to_datetime(test_kaggle.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day_length', 'DewPoint_lag_1', 'Sunrise', 'WetBulb_lag_1',\n",
       "       'AvgSpeed_lag_14', 'Tmin_lag_1', 'DewPoint_lag_7', 'DewPoint',\n",
       "       'Tavg_lag_14', 'ResultSpeed_lag_7', 'Tmin_lag_14', 'WetBulb_lag_7',\n",
       "       'WetBulb', 'ResultSpeed_lag_14', 'Tmin_lag_7', 'WetBulb_lag_14',\n",
       "       'Tavg_lag_1', 'SeaLevel_lag_3', 'Tmin', 'Tmax_lag_14', 'Sunset',\n",
       "       'Tavg_lag_7', 'Tavg', 'DewPoint_lag_14', 'Longitude', 'AvgSpeed_lag_7',\n",
       "       'Cool', 'Depart', 'Heat', 'DewPoint_lag_3', 'Tmax_lag_1',\n",
       "       'PrecipTotal_lag_1', 'Tmax', 'ResultSpeed', 'ResultSpeed_lag_1',\n",
       "       'ResultDir_lag_1', 'Tmax_lag_7', 'PrecipTotal_lag_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_eng = test_kaggle.merge(final_weather, on='Date')\n",
    "test_feat_eng['day_length'] = test_feat_eng.apply(day_length, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 74)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day_length', 'DewPoint_lag_1', 'Sunrise', 'WetBulb_lag_1',\n",
       "       'AvgSpeed_lag_14', 'Tmin_lag_1', 'DewPoint_lag_7', 'DewPoint',\n",
       "       'Tavg_lag_14', 'ResultSpeed_lag_7', 'Tmin_lag_14', 'WetBulb_lag_7',\n",
       "       'WetBulb', 'ResultSpeed_lag_14', 'Tmin_lag_7', 'WetBulb_lag_14',\n",
       "       'Tavg_lag_1', 'SeaLevel_lag_3', 'Tmin', 'Tmax_lag_14', 'Sunset',\n",
       "       'Tavg_lag_7', 'Tavg', 'DewPoint_lag_14', 'Longitude', 'AvgSpeed_lag_7',\n",
       "       'Cool', 'Depart', 'Heat', 'DewPoint_lag_3', 'Tmax_lag_1',\n",
       "       'PrecipTotal_lag_1', 'Tmax', 'ResultSpeed', 'ResultSpeed_lag_1',\n",
       "       'ResultDir_lag_1', 'Tmax_lag_7', 'PrecipTotal_lag_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 38)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat_eng = test_feat_eng[columns_high_corr]\n",
    "test_feat_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 38)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98309036, 0.01690964],\n",
       "       [0.98309036, 0.01690964],\n",
       "       [0.98309036, 0.01690964],\n",
       "       [0.98309036, 0.01690964],\n",
       "       [0.98309036, 0.01690964]])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kaggle_pred = gbc.predict_proba(test_feat_eng)\n",
    "test_kaggle_pred[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GBC submission **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(gbc.predict_proba(test_feat_eng)[:,1], columns = ['WnvPresent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.set_index(np.arange(1, test_feat_eng.shape[0] + 1), inplace=True)\n",
    "submission = submission.reset_index().rename(columns = {'index':'Id'})\n",
    "submission.to_csv('./submission_gbc_default.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82117\n",
       "1    34176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38268855391124146"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression\n",
    "44504 / (71789 + 44504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116293"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "71789 + 44504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
