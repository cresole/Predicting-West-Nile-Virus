## Executive Summary

Every year, people in Chicago are diagnosed with the West Nile Virus. The virus is spread by mosquitoes of the Culex species. While less than one percent of people infected by West Nile virus develop life-threatening symptoms, people over the age of 60 are at the highest risk especially patients with kidney conditions, diabetes, high blood pressure, or a weakened immune system. In hopes of reducing West Nile virus outbreaks, public health workers set up mosquito traps around Chicagoland every year from late spring to fall to trap mosquitoes and then detect the mosquitoes infected with West Nile virus. Using past West Nile mosquito data, we will predict which parts of Chicagoland West Nile mosquitoes will be and we will predict at what times we will detect these occurrences. 

As with any data science problem, exploring the data is the most important process before stating a solution. To start this study, we will use data about Chicago weather,  Chicago mosquitoes, and Chicago mosquito traps. We first clean the three data sources for any missing or invalid measurements. Also, our Chicago weather dataset contains measurements from two different stations. To take into account both reported values from the two stations, we will average both temperatures. After this step, we engineer some features to better quantify how the weather impacts the mosquito population in Chicago. To quantify the relationship between weather and the Chicago mosquito population, we incorporate weather conditions from previous days. Studying the data, we see that the weather conditions from the past days are strongly correlated with the life cycle and survivability of the insect. In one instance, we wanted to see how the precipitation from three days ago impacts mosquito growth as that happens to be the time needed for mosquito eggs to hatch. After engineering some features in our data, we are now ready for mathematical modeling. 

In our three sources of data, we divided them into two sets: training and testing. We used the training data to train our model to make more accurate predictions and we used the test data to see how accurate our model was on unseen data. Our model, also called a classifier, identified salient predictors in the training data and assigned probabilities to entries in the unseen test data. To assess how accurate our model was, we used a scoring metric called an Receiver Operating Characteristic(ROC) Curve. The ROC curve plots predictions using true positive and false positive rates. The ROC curve ranged from 0 to 1 where 0 says our model had all false positives and 1 says our model had all true positives. 0.5 is the baseline score and such a score suggests your model has as many true positives as false positives. The closer to 1 our score was, the more accurate our model was at accurately identifying West Nile virus cases in Chicagoland. On the unseen testing data, our model scored 0.74, suggesting that while our model is not perfect, it accurately identifies West Nile virus cases in most instances. 
